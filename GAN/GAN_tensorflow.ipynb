{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pixels = 28 * 28\n",
    "\n",
    "# Placeholders --> Gateways\n",
    "X = tf.placeholder(tf.float32, shape = ([None, n_pixels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variables(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variables(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def FC_layer(X, w, b):\n",
    "    return tf.matmul(X, w) + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder \n",
    "- Latent_dimensionality ==> Hyperparameter --> The number of dimensions we want, we're doing hit and try for this.\n",
    "- hidden_dimensionality ==> Number of neurons in input layers\n",
    "- mu --> Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 20\n",
    "h_dim = 500\n",
    "\n",
    "# 2 layer feed froward eural network\n",
    "# Layer 1:  \n",
    "w_enc = weight_variables([n_pixels, h_dim], 'w_enc')  # Tensor\n",
    "b_enc = bias_variables([h_dim], 'b_enc')  # Tensor\n",
    "# tanh --> Activation funtion(range : (-1 to 1)), It avoids vanishing gradient problem\n",
    "h_enc = tf.nn.tanh(FC_layer(X, w_enc, b_enc))\n",
    "\n",
    "# Layer 2: \n",
    "w_mu = weight_variables([h_dim, latent_dim], 'w_mu')  # Tensor\n",
    "b_mu = bias_variables([latent_dim], 'b_mu')  # Tensor\n",
    "# tanh --> Activation funtion(range : (-1 to 1)), It avoids vanishing gradient problem\n",
    "mu = FC_layer(h_enc, w_mu, b_mu) #mean\n",
    "\n",
    "\n",
    "# Compute partial derivatives w.r.t our input values given our weight and bias\n",
    "# Standard Deviation : \n",
    "w_logstd = weight_variables([h_dim, latent_dim], 'w_logstd')  # Tensor\n",
    "b_logstd = bias_variables([latent_dim], 'b_logstd')  # Tensor\n",
    "# tanh --> Activation funtion(range : (-1 to 1)), It avoids vanishing gradient problem\n",
    "logstd = FC_layer(h_enc, w_logstd, b_logstd) #std\n",
    "\n",
    "\n",
    "# Randomness:\n",
    "noise = tf.random_normal([1, latent_dim])\n",
    "\n",
    "# This is the ouput\n",
    "z = mu + tf.multiply(noise, tf.exp(.5*logstd))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "\n",
    "#layer 1\n",
    "W_dec = weight_variables([latent_dim, h_dim], 'W_dec')\n",
    "b_dec = bias_variables([h_dim], 'b_dec')\n",
    "#pass in z here (and the weights and biases we just defined)\n",
    "h_dec = tf.nn.tanh(FC_layer(z, W_dec, b_dec))\n",
    "\n",
    "\n",
    "#layer 2, using the original n pixels here since thats the dimensiaonlty\n",
    "#we want to restore our data to\n",
    "W_reconstruct = weight_variables([h_dim, n_pixels], 'W_reconstruct')\n",
    "b_reconstruct = bias_variables([n_pixels], 'b_reconstruct')\n",
    "#784 bernoulli parameters output\n",
    "reconstruction = tf.nn.sigmoid(FC_layer(h_dec, W_reconstruct, b_reconstruct))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets define our loss function\n",
    "\n",
    "# variational lower bound\n",
    "\n",
    "# add epsilon to log to prevent numerical overflow\n",
    "#Information is lost because it goes from a smaller to a larger dimensionality. \n",
    "#How much information is lost? We measure this using the reconstruction log-likelihood \n",
    "#This measure tells us how effectively the decoder has learned to reconstruct\n",
    "#an input image x given its latent representation z.\n",
    "log_likelihood = tf.reduce_sum(X*tf.log(reconstruction + 1e-9)+(1 - X)*tf.log(1 - reconstruction + 1e-9), reduction_indices=1)\n",
    "#KL Divergence\n",
    "#If the encoder outputs representations z that are different \n",
    "#than those from a standard normal distribution, it will receive \n",
    "#a penalty in the loss. This regularizer term means \n",
    "#‘keep the representations z of each digit sufficiently diverse’. \n",
    "#If we didn’t include the regularizer, the encoder could learn to cheat\n",
    "#and give each datapoint a representation in a different region of Euclidean space. \n",
    "KL_term = -.5*tf.reduce_sum(1 + 2*logstd - tf.pow(mu,2) - tf.exp(2*logstd), reduction_indices=1)\n",
    "\n",
    "# This allows us to use stochastic gradient descent with respect to the variational parameters\n",
    "variational_lower_bound = tf.reduce_mean(log_likelihood - KL_term)\n",
    "optimizer = tf.train.AdadeltaOptimizer().minimize(-variational_lower_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init all variables and start the session!\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "## Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: -947.5431518554688\n"
     ]
    }
   ],
   "source": [
    "import time #lets clock training time..\n",
    "\n",
    "num_iterations = 1000\n",
    "recording_interval = 1000\n",
    "#store value for these 3 terms so we can plot them later\n",
    "variational_lower_bound_array = []\n",
    "log_likelihood_array = []\n",
    "KL_term_array = []\n",
    "\n",
    "# type(num_iterations/recording_interval)\n",
    "iteration_array = [i*recording_interval for i in range(int(num_iterations/recording_interval))]\n",
    "for i in range(num_iterations):\n",
    "    # np.round to make MNIST binary\n",
    "    #get first batch (200 digits)\n",
    "    x_batch = np.round(mnist.train.next_batch(200)[0])\n",
    "    #run our optimizer on our data\n",
    "    sess.run(optimizer, feed_dict={X: x_batch})\n",
    "    if (i%recording_interval == 0):\n",
    "        #every 1K iterations record these values\n",
    "        vlb_eval = variational_lower_bound.eval(feed_dict={X: x_batch})\n",
    "        print (\"Iteration: {}, Loss: {}\".format(i, vlb_eval))\n",
    "        variational_lower_bound_array.append(vlb_eval)\n",
    "        log_likelihood_array.append(np.mean(log_likelihood.eval(feed_dict={X: x_batch})))\n",
    "        KL_term_array.append(np.mean(KL_term.eval(feed_dict={X: x_batch})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iteration_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss per iteration')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "#for the number of iterations we had \n",
    "#plot these 3 terms\n",
    "plt.plot(iteration_array, variational_lower_bound_array)\n",
    "plt.plot(iteration_array, KL_term_array)\n",
    "plt.plot(iteration_array, log_likelihood_array)\n",
    "plt.legend(['Variational Lower Bound', 'KL divergence', 'Log Likelihood'], bbox_to_anchor=(1.05, 1), loc=2)\n",
    "plt.title('Loss per iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "load_model = False\n",
    "if load_model:\n",
    "    saver.restore(sess, os.path.join(os.getcwd(), \"Trained Bernoulli VAE\"))\n",
    "\n",
    "num_pairs = 10\n",
    "image_indices = np.random.randint(0, 200, num_pairs)\n",
    "#Lets plot 10 digits\n",
    "for pair in range(num_pairs):\n",
    "    #reshaping to show original test image\n",
    "    x = np.reshape(mnist.test.images[image_indices[pair]], (1,n_pixels))\n",
    "    plt.figure()\n",
    "    x_image = np.reshape(x, (28,28))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(x_image)\n",
    "    #reconstructed image, feed the test image to the decoder\n",
    "    x_reconstruction = reconstruction.eval(feed_dict={X: x})\n",
    "    #reshape it to 28x28 pixels\n",
    "    x_reconstruction_image = (np.reshape(x_reconstruction, (28,28)))\n",
    "    #plot it!\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(x_reconstruction_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
