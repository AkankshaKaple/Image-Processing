{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "snOyI-dXs4mg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3w-UxI68s4ml"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 112, 3), 200)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = 112\n",
    "col = 112\n",
    "channels = 3\n",
    "latent_dim = 200\n",
    "img_shape = (row, col, channels)\n",
    "img_shape, latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rM61LZHls4mv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0711 15:02:32.387472 139661724616512 deprecation_wrapper.py:119] From /home/administrator123/anaconda3/envs/Image_Processing/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0711 15:02:32.435373 139661724616512 deprecation_wrapper.py:119] From /home/administrator123/anaconda3/envs/Image_Processing/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0711 15:02:32.443049 139661724616512 deprecation_wrapper.py:119] From /home/administrator123/anaconda3/envs/Image_Processing/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0711 15:02:32.484111 139661724616512 deprecation_wrapper.py:119] From /home/administrator123/anaconda3/envs/Image_Processing/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0711 15:02:32.516138 139661724616512 deprecation_wrapper.py:119] From /home/administrator123/anaconda3/envs/Image_Processing/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0711 15:02:32.516747 139661724616512 deprecation_wrapper.py:119] From /home/administrator123/anaconda3/envs/Image_Processing/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0711 15:02:32.898509 139661724616512 deprecation_wrapper.py:119] From /home/administrator123/anaconda3/envs/Image_Processing/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0711 15:02:33.242109 139661724616512 deprecation.py:506] From /home/administrator123/anaconda3/envs/Image_Processing/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 401408)            80683008  \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 56, 56, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 128)       589952    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 64)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 112, 112, 3)       0         \n",
      "=================================================================\n",
      "Total params: 81,349,251\n",
      "Trainable params: 81,348,867\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 29, 29, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 15, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 15, 15, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 15, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 57601     \n",
      "=================================================================\n",
      "Total params: 447,809\n",
      "Trainable params: 446,913\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f04f77d4588>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DCNN : For upsampling\n",
    "def build_generator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(512 * 28 * 28, activation=\"relu\", input_dim=latent_dim))\n",
    "    model.add(Reshape((28, 28, 512)))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)\n",
    "\n",
    "build_generator()\n",
    "\n",
    "def build_discriminator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)\n",
    "build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JEX87Cans4m0",
    "outputId": "6aeb1228-c299-40a1-d7f3-b76a921a03d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 56, 56, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 29, 29, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 15, 15, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 15, 15, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 15, 15, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 57601     \n",
      "=================================================================\n",
      "Total params: 447,809\n",
      "Trainable params: 446,913\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0711 15:02:34.721603 139661724616512 deprecation_wrapper.py:119] From /home/administrator123/anaconda3/envs/Image_Processing/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0711 15:02:34.736473 139661724616512 deprecation.py:323] From /home/administrator123/anaconda3/envs/Image_Processing/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 401408)            80683008  \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 56, 56, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 56, 56, 128)       589952    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 112, 112, 64)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 112, 112, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 112, 112, 3)       0         \n",
      "=================================================================\n",
      "Total params: 81,349,251\n",
      "Trainable params: 81,348,867\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "(?, 112, 112, 3) Tensor(\"input_5:0\", shape=(?, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "\n",
    "# The generator takes noise as input and generates imgs\n",
    "z = Input(shape=(latent_dim,))\n",
    "img = generator(z)\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "print(img.shape, z)\n",
    "# The discriminator takes generated images as input and determines validity\n",
    "valid = discriminator(img)\n",
    "\n",
    "# The combined model  (stacked generator and discriminator)\n",
    "# Trains the generator to fool the discriminator\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7xokVz7s4m4"
   },
   "outputs": [],
   "source": [
    "def save_imgs(epoch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/pokemon_%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bjDsu7Nks4m6"
   },
   "outputs": [],
   "source": [
    "def train(epochs, batch_size=128, save_interval=500):\n",
    "\n",
    "    \n",
    "    X = np.zeros((112,112,3))\n",
    "    \n",
    "    instances = []\n",
    "\n",
    "    # Load in the images\n",
    "    for filepath in os.listdir('/home/administrator123/Akanksha/CNN/GAN/Pokemon/data/'):\n",
    "#         instances.append(cv2.imread('/home/administrator123/Akanksha/CNN/GAN/Pokemon/data/'))       \n",
    "        img = cv2.imread('/home/administrator123/Akanksha/CNN/GAN/Pokemon/data/' + filepath)\n",
    "        img = cv2.resize(img, (112,112))\n",
    "        instances.append(img)\n",
    "              \n",
    "    X_train = np.array(instances)\n",
    "    print(X_train.shape)\n",
    "    \n",
    "    # Rescale -1 to 1\n",
    "    X_train = X_train / 127.5 - 1.\n",
    "#     X_train = np.expand_dims(X_train, axis=3)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "\n",
    "    # Adversarial ground truths\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a batch of new images\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Train the discriminator (real classified as ones and generated as zeros)\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        # Train the generator (wants discriminator to mistake images as real)\n",
    "        g_loss = combined.train_on_batch(noise, valid)\n",
    "\n",
    "        # Plot the progress\n",
    "        if epoch % 1000 == 0 :\n",
    "          print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % save_interval == 0:\n",
    "            save_imgs(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "MWlzdx3is4m-",
    "outputId": "ccde8a29-fd2a-454a-be52-9db7b5274f64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 112, 112, 3)\n",
      "(100, 112, 112, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator123/anaconda3/envs/Image_Processing/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 1.226326, acc.: 45.31%] [G loss: 1.722779]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "train(epochs=400000, batch_size=32, save_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eXakOrRhC9dR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pokemon.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
